{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6efd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import fm_models\n",
    "import signal_gen\n",
    "import utils\n",
    "import config\n",
    "importlib.reload(signal_gen)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(config)\n",
    "importlib.reload(fm_models)\n",
    "from signal_gen import RFSignalDataset\n",
    "from fm_models import RFSignalDiT\n",
    "from utils import get_classifier_model\n",
    "from config import CONFIG, DEVICE\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "fm_model = RFSignalDiT().to(DEVICE)\n",
    "fm_model.load_state_dict(torch.load(\"/root/code/flow_matching/checkpoints/01-19--11-23/model_final.pth\", map_location=DEVICE))\n",
    "classifier_model = get_classifier_model().to(DEVICE)\n",
    "classifier_model.load_state_dict(torch.load('/root/code/flow_matching/checkpoints/01-27--21-32/classifier_samples_1800000.pth', map_location=DEVICE))\n",
    "#========\n",
    "classifier_model_ft = get_classifier_model().to(DEVICE)\n",
    "# classifier_model_ft.load_state_dict(torch.load('/root/code/flow_matching/checkpoints/01-25--20-19/classifier_finetuned_final.pth', map_location=DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e3001a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 配置评估参数 ---\n",
    "# SNR 扫描范围：从 x dB 到 x dB\n",
    "snr_range = np.arange(-10, 5+1, 1) \n",
    "\n",
    "# 每个 SNR 点评估的 batch 数量 (求平均以获得稳定结果)\n",
    "batch_size = 100 * CONFIG[\"num_classes\"] # num per class * num_classes in each SNR\n",
    "# 准备一个\"干净\"的数据集源，用于在评估时手动添加指定 SNR 的噪声\n",
    "# 这样我们可以严格控制评估时的 SNR 和 t 的对应关系\n",
    "clean_dataset = RFSignalDataset(num_samples=int(1e5), snr_range=None,seed=100)\n",
    "clean_loader = DataLoader(clean_dataset, batch_size=batch_size)\n",
    "iter_clean_loader = iter(clean_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97e7066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_awgn(sig, snr_db):\n",
    "    \"\"\"在信号上添加指定 SNR 的高斯白噪声，并重新归一化功率\"\"\"\n",
    "    # 假设输入信号 sig 已经功率归一化 (Ps = 1)\n",
    "    # SNR = 10 * log10(Ps / Pn)  =>  Pn = Ps / 10^(SNR/10)\n",
    "    power_noise = 1.0 / (10**(snr_db / 10.0))\n",
    "    \n",
    "    # 对于复数信号，总噪声功率由 I 和 Q 共同贡献\n",
    "    # Pn = Var(I) + Var(Q) = sigma^2 + sigma^2 = 2 * sigma^2\n",
    "    # 因此每个分量的方差应为 Pn / 2\n",
    "    noise_std = torch.sqrt(torch.tensor(power_noise / 2.0, device=sig.device))\n",
    "    \n",
    "    # randn_like 生成标准正态分布 (mean=0, std=1)\n",
    "    noise = torch.randn_like(sig) * noise_std\n",
    "    noisy_sig = sig + noise\n",
    "\n",
    "    # 重新归一化功率\n",
    "    energy = torch.sum(noisy_sig**2, dim=(1, 2), keepdim=True)\n",
    "    length = noisy_sig.shape[2] # L\n",
    "    power_noisy = energy / length\n",
    "    \n",
    "    noisy_sig = noisy_sig / torch.sqrt(power_noisy + 1e-8)\n",
    "\n",
    "    return noisy_sig\n",
    "\n",
    "def snr2t(snr_db):\n",
    "    \"\"\"根据 SNR 计算扩散时间步 t\"\"\"\n",
    "    R = 10 ** (snr_db / 20.0)\n",
    "    t = R / (1+R)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d8bf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 执行评估循环 ---\n",
    "from tqdm import tqdm\n",
    "acc_noisy_list = [0] * len(snr_range)\n",
    "acc_denoised_list = [0] * len(snr_range)\n",
    "acc_clean_list = [0] * len(snr_range)\n",
    "confusion_data = {\n",
    "    -5: {'clean': [], 'noisy': [], 'denoised': [], 'label': []},\n",
    "    0:  {'clean': [], 'noisy': [], 'denoised': [], 'label': []},\n",
    "    5: {'clean': [], 'noisy': [], 'denoised': [], 'label': []}\n",
    "}\n",
    "\n",
    "# 使用 no_grad context 避免梯度计算占用显存\n",
    "with torch.no_grad():\n",
    "    for idx, snr in tqdm(enumerate(snr_range),total=len(snr_range)):\n",
    "        sig, label, _ = next(iter_clean_loader)\n",
    "        noisy_sig = add_awgn(sig, snr_db=snr)\n",
    "        sig, label = sig.to(DEVICE), label.to(DEVICE)\n",
    "        noisy_sig = noisy_sig.to(DEVICE)\n",
    "        N = sig.shape[0]\n",
    "        \n",
    "        # Eval clean sig\n",
    "        logits = classifier_model(sig)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        correct = (label == preds).sum().item()\n",
    "        acc_clean_list[idx] = correct / N\n",
    "\n",
    "        # Eval noisy sig (Directly to classifier)\n",
    "        logits_noisy = classifier_model(noisy_sig)\n",
    "        preds_noisy = torch.argmax(logits_noisy, dim=1)\n",
    "        correct_noisy = (label == preds_noisy).sum().item()\n",
    "        acc_noisy_list[idx] = correct_noisy / N\n",
    "\n",
    "        # Eval Denoised sig (Through FM)\n",
    "        t = snr2t(snr)\n",
    "        scale_factor = torch.sqrt(torch.tensor((1 - t)**2 + t**2, device=noisy_sig.device))\n",
    "        # 进行去噪推理\n",
    "        step = int((1-t)/1.0 * 50) #TODO: more steps for better quality\n",
    "        sig_denoised = fm_model.predict_x1(noisy_sig * scale_factor, t_start=t, steps=step)\n",
    "        logits_denoised = classifier_model(sig_denoised)\n",
    "        preds_denoised = torch.argmax(logits_denoised, dim=1)\n",
    "        correct_denoised = (label == preds_denoised).sum().item()\n",
    "        acc_denoised_list[idx] = correct_denoised / N\n",
    "        \n",
    "        if snr in confusion_data:\n",
    "            # 收集预测结果 \n",
    "            confusion_data[snr]['clean'].append(preds.cpu().numpy())\n",
    "            confusion_data[snr]['noisy'].append(preds_noisy.cpu().numpy())\n",
    "            confusion_data[snr]['denoised'].append(preds_denoised.cpu().numpy())\n",
    "            confusion_data[snr]['label'].append(label.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efb234a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 绘制评估结果曲线 ---\n",
    "plt.figure(figsize=(10, 6), dpi=100)\n",
    "\n",
    "# 1. 绘制 Upper Bound (Clean Signal)\n",
    "# 注意：acc_clean_list 在每个 SNR 循环里都计算了一次，理论上应该是差不多的（只是因为每次采样batch不同会有微小波动）\n",
    "plt.plot(snr_range, acc_clean_list, 'g--', linewidth=1.5, alpha=0.6, label=f'Clean Baseline ')\n",
    "\n",
    "# 2. 绘制 Flow Matching Denoised 结果\n",
    "plt.plot(snr_range, acc_denoised_list, 'b-o', linewidth=2, label='With FM Denoising')\n",
    "\n",
    "# 3. 绘制 Lower Bound (Noisy Signal)\n",
    "plt.plot(snr_range, acc_noisy_list, 'r-s', linewidth=2, label='Noisy Signal (Direct)')\n",
    "\n",
    "plt.xlabel(\"SNR (dB)\", fontsize=12)\n",
    "plt.ylabel(\"Classification Accuracy\", fontsize=12)\n",
    "plt.title(\"Impact of Flow Matching Denoising on Modulation Classification\", fontsize=14)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.legend(fontsize=11)\n",
    "plt.xticks(snr_range)\n",
    "plt.ylim(0, 1.05)  # Accuracy is 0-1\n",
    "plt.yticks(np.arange(0, 1.1, 0.05)) # 设置 y 轴刻度间隔为 0.1\n",
    "\n",
    "# 标注提升幅度\n",
    "for i, snr in enumerate(snr_range):\n",
    "    # 计算提升百分比\n",
    "    gain = acc_denoised_list[i] - acc_noisy_list[i]\n",
    "    if gain > 0.05: # 只标注提升超过 5% 的点，避免图表太乱\n",
    "        plt.annotate(f\"+{gain*100:.1f}%\", \n",
    "                     (snr, acc_denoised_list[i]), \n",
    "                     textcoords=\"offset points\", \n",
    "                     xytext=(0, 10), \n",
    "                     ha='center',\n",
    "                     color='blue',\n",
    "                     fontweight='bold',\n",
    "                     fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac00195",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "snrs = sorted(confusion_data.keys())\n",
    "# squeeze=False 保证 axes 始终是 2D 数组，避免 1 行时的 shape 问题\n",
    "# 修改列数为2，只显示 Noisy 和 Denoised\n",
    "fig, axes = plt.subplots(len(snrs), 2, figsize=(12, 5 * len(snrs)), constrained_layout=True, squeeze=False)\n",
    "class_names = clean_dataset.mod_types\n",
    "\n",
    "for i, snr in enumerate(snrs):\n",
    "    # 拼接当前 SNR 下的所有 batch 数据\n",
    "    y_true = np.concatenate(confusion_data[snr]['label'])\n",
    "    scenarios = [\n",
    "        # 去掉 Clean，只保留 Noisy 和 Denoised\n",
    "        ('Noisy',    np.concatenate(confusion_data[snr]['noisy']),    'Blues'),\n",
    "        ('Denoised', np.concatenate(confusion_data[snr]['denoised']), 'Blues')\n",
    "    ]\n",
    "    \n",
    "    for j, (title, y_pred, cmap) in enumerate(scenarios):\n",
    "        cm = confusion_matrix(y_true, y_pred, normalize='true')\n",
    "        disp = ConfusionMatrixDisplay(cm, display_labels=class_names)\n",
    "        # vmin/vmax=0/1 确保热力图颜色范围一致\n",
    "        disp.plot(ax=axes[i, j], cmap=cmap, include_values=False, xticks_rotation=90)\n",
    "        axes[i, j].set_title(f\"{title} (SNR={snr}dB)\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
